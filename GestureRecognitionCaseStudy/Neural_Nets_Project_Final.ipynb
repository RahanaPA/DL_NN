{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GogleDrive-Link for the Model(.h5 files) with Good Accuracy <br>\n",
    "\n",
    "CNN+RNN Stack using GRU -- train accuracy = 93.84% And Validation Accuracy = 93.75% <br>\n",
    "https://drive.google.com/open?id=1JSUj7mxOwbD-nqseNIVZwWDEDMY_JuO2 <br>\n",
    "\n",
    "Conv3D  -- train accuracy = 79.2% And Validation Accuracy = 81.2% <br>\n",
    "https://drive.google.com/open?id=1T27pUpS-hVxGqhUQDwhmzRqRvCW3dXFs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread, imresize\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('./Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('./Project_data/val.csv').readlines())\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 5 #left swipe, right swipe, thumbs up, thumbs down, stop\n",
    "n_channel = 3\n",
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "     #create a list of image numbers you want to use for a particular video\n",
    "    img_idx = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,x,y,z,n_channel)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,n_classes)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    \n",
    "                    tempimg = imresize(image,(y,z))\n",
    "                     \n",
    "                    tempimg = tempimg/127.5-1 #Normalize data\n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (tempimg[:,:,0]) #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,1] = (tempimg[:,:,1]) #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = (tempimg[:,:,2]) #normalise and feed in the image\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            print(\"Batch: \",num_batches+1,\"Index:\", batch_size)\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            batch_data = np.zeros((batch_size,x,y,z,n_channel)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,n_classes)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    tempimg = imresize(image,(y,z))\n",
    "                     \n",
    "                    tempimg = tempimg/127.5-1 #Normalize data\n",
    "                                        \n",
    "                    batch_data[folder,idx,:,:,0] = (tempimg[:,:,0])\n",
    "                    batch_data[folder,idx,:,:,1] = (tempimg[:,:,1])\n",
    "                    batch_data[folder,idx,:,:,2] = (tempimg[:,:,2])\n",
    "                   \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 20\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = './Project_data/train'\n",
    "val_path = './Project_data/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 20 # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout,LSTM\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp :1- Model1 with number of frames,image width,image height are (30,120,120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#write your model here\n",
    "#model 1\n",
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(Conv3D(8, #number of filters \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=(30, 120, 120, 3),\n",
    "                 padding='same'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "model_1.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_1.add(Conv3D(16, #Number of filters, \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "model_1.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_1.add(Conv3D(32, #Number of filters \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "model_1.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_1.add(Conv3D(64, #Number pf filters \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "model_1.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model_1.add(Flatten())\n",
    "\n",
    "model_1.add(Dense(1000, activation='relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "\n",
    "model_1.add(Dense(500, activation='relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model_1.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1000)              3137000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 3,667,749\n",
      "Trainable params: 3,667,509\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = optimizers.Adam(lr=0.001) #write your optimizer\n",
    "model_1.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ./Project_data/val ; batch size = 32\n",
      "Source path =  ./Project_data/train ; batch size = 32\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/21 [===>..........................] - ETA: 1:31 - loss: 6.0817 - categorical_accuracy: 0.2083Batch:  4 Index: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/21 [==========================>...] - ETA: 7s - loss: 4.9039 - categorical_accuracy: 0.2681 Batch:  21 Index: 32\n",
      "21/21 [==============================] - 83s 4s/step - loss: 4.6679 - categorical_accuracy: 0.2801 - val_loss: 2.4683 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2215_29_19.738318/model-00001-4.69905-0.27753-2.46831-0.33000.h5\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - 51s 2s/step - loss: 2.2017 - categorical_accuracy: 0.3706 - val_loss: 6.8251 - val_categorical_accuracy: 0.0625\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2215_29_19.738318/model-00002-2.20166-0.37060-6.82512-0.06250.h5\n",
      "Epoch 3/20\n",
      " 6/21 [=======>......................] - ETA: 40s - loss: 1.6593 - categorical_accuracy: 0.4348Batch:  29 Index: 23\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.6493 - categorical_accuracy: 0.4177 - val_loss: 1.6799 - val_categorical_accuracy: 0.3125\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2215_29_19.738318/model-00003-1.64765-0.41920-1.67987-0.31250.h5\n",
      "Epoch 4/20\n",
      "20/21 [===========================>..] - ETA: 2s - loss: 1.3665 - categorical_accuracy: 0.4184Batch:  35 Index: 19\n",
      "21/21 [==============================] - 46s 2s/step - loss: 1.3601 - categorical_accuracy: 0.4185 - val_loss: 1.4413 - val_categorical_accuracy: 0.3125\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2215_29_19.738318/model-00004-1.36010-0.41855-1.44134-0.31250.h5\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - 41s 2s/step - loss: 1.3940 - categorical_accuracy: 0.4454 - val_loss: 1.0254 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2215_29_19.738318/model-00005-1.39397-0.44538-1.02536-0.50000.h5\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - 41s 2s/step - loss: 1.2985 - categorical_accuracy: 0.4734 - val_loss: 0.9432 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2215_29_19.738318/model-00006-1.29850-0.47339-0.94316-0.62500.h5\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - 42s 2s/step - loss: 1.1682 - categorical_accuracy: 0.4874 - val_loss: 1.0101 - val_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2215_29_19.738318/model-00007-1.16824-0.48739-1.01015-0.56250.h5\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - 40s 2s/step - loss: 1.2025 - categorical_accuracy: 0.4706 - val_loss: 1.0404 - val_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2215_29_19.738318/model-00008-1.20250-0.47059-1.04040-0.56250.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - 41s 2s/step - loss: 1.0970 - categorical_accuracy: 0.5238 - val_loss: 1.2166 - val_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-2215_29_19.738318/model-00009-1.09698-0.52381-1.21664-0.56250.h5\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - 41s 2s/step - loss: 1.0962 - categorical_accuracy: 0.5154 - val_loss: 0.8795 - val_categorical_accuracy: 0.6875\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-2215_29_19.738318/model-00010-1.09624-0.51541-0.87947-0.68750.h5\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - 39s 2s/step - loss: 0.9957 - categorical_accuracy: 0.5938 - val_loss: 1.1787 - val_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-2215_29_19.738318/model-00011-0.99571-0.59384-1.17873-0.56250.h5\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - 40s 2s/step - loss: 0.9571 - categorical_accuracy: 0.5994 - val_loss: 0.8525 - val_categorical_accuracy: 0.8125\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-2215_29_19.738318/model-00012-0.95706-0.59944-0.85247-0.81250.h5\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - 41s 2s/step - loss: 0.9885 - categorical_accuracy: 0.6218 - val_loss: 1.0980 - val_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-2215_29_19.738318/model-00013-0.98847-0.62185-1.09798-0.56250.h5\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - 42s 2s/step - loss: 0.8506 - categorical_accuracy: 0.6415 - val_loss: 0.8949 - val_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-2215_29_19.738318/model-00014-0.85061-0.64146-0.89491-0.56250.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - 41s 2s/step - loss: 0.8313 - categorical_accuracy: 0.6667 - val_loss: 0.7864 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-2215_29_19.738318/model-00015-0.83133-0.66667-0.78636-0.75000.h5\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - 41s 2s/step - loss: 0.7194 - categorical_accuracy: 0.7031 - val_loss: 0.8895 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-2215_29_19.738318/model-00016-0.71942-0.70308-0.88950-0.75000.h5\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - 41s 2s/step - loss: 0.7719 - categorical_accuracy: 0.7283 - val_loss: 1.0204 - val_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-2215_29_19.738318/model-00017-0.77193-0.72829-1.02042-0.56250.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - 41s 2s/step - loss: 0.7724 - categorical_accuracy: 0.6751 - val_loss: 0.6517 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-2215_29_19.738318/model-00018-0.77237-0.67507-0.65174-0.75000.h5\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - 41s 2s/step - loss: 0.6287 - categorical_accuracy: 0.7591 - val_loss: 0.8978 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-2215_29_19.738318/model-00019-0.62873-0.75910-0.89783-0.75000.h5\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - 42s 2s/step - loss: 0.6494 - categorical_accuracy: 0.7535 - val_loss: 0.6283 - val_categorical_accuracy: 0.6875\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-2215_29_19.738318/model-00020-0.64938-0.75350-0.62830-0.68750.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd7da6e88d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp :2-  Model2 with same number of frames,image width,image height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 5 #left swipe, right swipe, thumbs up, thumbs down, stop\n",
    "n_channel = 3\n",
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_13 (Conv3D)           (None, 30, 120, 120, 32)  2624      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 30, 120, 120, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_14 (Conv3D)           (None, 30, 120, 120, 32)  27680     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 30, 120, 120, 32)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 10, 40, 40, 64)    55360     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 10, 40, 40, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_16 (Conv3D)           (None, 10, 40, 40, 64)    110656    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10, 40, 40, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 4, 14, 14, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 4, 14, 14, 64)     0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               25690624  \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 25,889,509\n",
      "Trainable params: 25,889,509\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define model b\n",
    "model_2 = Sequential()\n",
    "model_2.add(Conv3D(32, kernel_size=(3, 3, 3), input_shape=(x,y,z,n_channel), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Conv3D(32, kernel_size=(3, 3, 3), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
    "model_2.add(Dropout(0.25))\n",
    "\n",
    "model_2.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
    "model_2.add(Dropout(0.25))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(512, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model_2.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ./Project_data/val ; batch size = 10\n",
      "Source path =  ./Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 47s 2s/step - loss: 1.9322 - categorical_accuracy: 0.1619 - val_loss: 1.5932 - val_categorical_accuracy: 0.2250\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2215_29_19.738318/model-00001-1.93221-0.16190-1.59323-0.22500.h5\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 38s 2s/step - loss: 1.5955 - categorical_accuracy: 0.1524 - val_loss: 1.6047 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2215_29_19.738318/model-00002-1.59546-0.15238-1.60470-0.20000.h5\n",
      "Epoch 3/10\n",
      "14/21 [===================>..........] - ETA: 11s - loss: 1.5958 - categorical_accuracy: 0.2429Batch:  67 Index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 38s 2s/step - loss: 1.5780 - categorical_accuracy: 0.2286 - val_loss: 1.4913 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2215_29_19.738318/model-00003-1.57804-0.22857-1.49128-0.25000.h5\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 21s 999ms/step - loss: 1.5758 - categorical_accuracy: 0.2290 - val_loss: 1.5503 - val_categorical_accuracy: 0.2250\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2215_29_19.738318/model-00004-1.55908-0.23810-1.55026-0.22500.h5\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 15s 707ms/step - loss: 1.5128 - categorical_accuracy: 0.3333 - val_loss: 1.6004 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2215_29_19.738318/model-00005-1.51279-0.33333-1.60041-0.20000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 15s 697ms/step - loss: 1.5277 - categorical_accuracy: 0.2381 - val_loss: 1.5261 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2215_29_19.738318/model-00006-1.52774-0.23810-1.52613-0.30000.h5\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 15s 696ms/step - loss: 1.4334 - categorical_accuracy: 0.3651 - val_loss: 1.4538 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2215_29_19.738318/model-00007-1.43343-0.36508-1.45380-0.30000.h5\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 15s 698ms/step - loss: 1.4155 - categorical_accuracy: 0.3333 - val_loss: 1.5737 - val_categorical_accuracy: 0.2250\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2215_29_19.738318/model-00008-1.41549-0.33333-1.57367-0.22500.h5\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 15s 697ms/step - loss: 1.4622 - categorical_accuracy: 0.3651 - val_loss: 1.4419 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-2215_29_19.738318/model-00009-1.46224-0.36508-1.44194-0.40000.h5\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 15s 697ms/step - loss: 1.4275 - categorical_accuracy: 0.3651 - val_loss: 1.4160 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-2215_29_19.738318/model-00010-1.42750-0.36508-1.41600-0.45000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd775989048>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs=10\n",
    "model_2.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp :3- Model 2 with Changing number of frames,image width,image height values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 5 #left swipe, right swipe, thumbs up, thumbs down, stop\n",
    "n_channel = 3\n",
    "x = 30 # number of frames\n",
    "y = 60 # image width\n",
    "z = 60 # image height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 60, 60, 32)    2624      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 30, 60, 60, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 10, 20, 20, 32)    0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 20, 20, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 10, 20, 20, 64)    55360     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 10, 20, 20, 64)    110656    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 4, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               6423040   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 6,621,925\n",
      "Trainable params: 6,621,925\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define model b\n",
    "model_2 = Sequential()\n",
    "model_2.add(Conv3D(32, kernel_size=(3, 3, 3), input_shape=(x,y,z,n_channel), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Conv3D(32, kernel_size=(3, 3, 3), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
    "model_2.add(Dropout(0.25))\n",
    "\n",
    "model_2.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
    "model_2.add(Dropout(0.25))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(512, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model_2.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)\n",
    "num_epochs=10\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ./Project_data/val ; batch size = 10\n",
      "Source path =  ./Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 25s 1s/step - loss: 1.6467 - categorical_accuracy: 0.2000 - val_loss: 1.6087 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2215_29_19.738318/model-00001-1.64673-0.20000-1.60869-0.20000.h5\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 21s 1s/step - loss: 1.6048 - categorical_accuracy: 0.2381 - val_loss: 1.5930 - val_categorical_accuracy: 0.2250\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2215_29_19.738318/model-00002-1.60476-0.23810-1.59303-0.22500.h5\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 22s 1s/step - loss: 1.6097 - categorical_accuracy: 0.1857 - val_loss: 1.6128 - val_categorical_accuracy: 0.1250\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2215_29_19.738318/model-00003-1.60972-0.18571-1.61284-0.12500.h5\n",
      "Epoch 4/10\n",
      " 2/21 [=>............................] - ETA: 24s - loss: 1.6124 - categorical_accuracy: 0.1000Batch:  67 Index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 11s 510ms/step - loss: 1.6053 - categorical_accuracy: 0.2655 - val_loss: 1.6116 - val_categorical_accuracy: 0.1250\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2215_29_19.738318/model-00004-1.60547-0.27381-1.61161-0.12500.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 7s 349ms/step - loss: 1.5392 - categorical_accuracy: 0.3968 - val_loss: 1.7682 - val_categorical_accuracy: 0.3250\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2215_29_19.738318/model-00005-1.53917-0.39683-1.76821-0.32500.h5\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 7s 337ms/step - loss: 1.6486 - categorical_accuracy: 0.1587 - val_loss: 1.6026 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2215_29_19.738318/model-00006-1.64863-0.15873-1.60260-0.25000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 7s 354ms/step - loss: 1.6098 - categorical_accuracy: 0.2063 - val_loss: 1.6111 - val_categorical_accuracy: 0.1750\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2215_29_19.738318/model-00007-1.60975-0.20635-1.61114-0.17500.h5\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 7s 357ms/step - loss: 1.6165 - categorical_accuracy: 0.2063 - val_loss: 1.6053 - val_categorical_accuracy: 0.2250\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2215_29_19.738318/model-00008-1.61647-0.20635-1.60526-0.22500.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 8s 375ms/step - loss: 1.6182 - categorical_accuracy: 0.0794 - val_loss: 1.6098 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-2215_29_19.738318/model-00009-1.61822-0.07937-1.60976-0.25000.h5\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 8s 367ms/step - loss: 1.6121 - categorical_accuracy: 0.2222 - val_loss: 1.6132 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-2215_29_19.738318/model-00010-1.61208-0.22222-1.61320-0.15000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd7746f5ac8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp :4- Model 2 with same number of frames,image width,image height values but changing Batch size  to 20 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, 20)\n",
    "val_generator = generator(val_path, val_doc, 20)\n",
    "num_epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/67 [=============>................] - ETA: 1:17 - loss: 1.6083 - categorical_accuracy: 0.2078Batch:  34 Index: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 84s 1s/step - loss: 1.6055 - categorical_accuracy: 0.2207 - val_loss: 1.6086 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2215_29_19.738318/model-00001-1.60748-0.20997-1.60862-0.21000.h5\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 28s 416ms/step - loss: 1.6114 - categorical_accuracy: 0.1891 - val_loss: 1.6083 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2215_29_19.738318/model-00002-1.61142-0.18905-1.60830-0.21000.h5\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 29s 438ms/step - loss: 1.6084 - categorical_accuracy: 0.1841 - val_loss: 1.6068 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2215_29_19.738318/model-00003-1.60840-0.18408-1.60683-0.21000.h5\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 29s 440ms/step - loss: 1.6031 - categorical_accuracy: 0.2736 - val_loss: 1.6006 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2215_29_19.738318/model-00004-1.60306-0.27363-1.60064-0.26000.h5\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 30s 442ms/step - loss: 1.5533 - categorical_accuracy: 0.2338 - val_loss: 1.5246 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2215_29_19.738318/model-00005-1.55330-0.23383-1.52464-0.18000.h5\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 29s 437ms/step - loss: 1.5191 - categorical_accuracy: 0.2488 - val_loss: 1.4977 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2215_29_19.738318/model-00006-1.51911-0.24876-1.49773-0.30000.h5\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 29s 438ms/step - loss: 1.5184 - categorical_accuracy: 0.2537 - val_loss: 1.4846 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2215_29_19.738318/model-00007-1.51835-0.25373-1.48458-0.29000.h5\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 29s 437ms/step - loss: 1.4803 - categorical_accuracy: 0.2537 - val_loss: 1.4390 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2215_29_19.738318/model-00008-1.48032-0.25373-1.43900-0.32000.h5\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 30s 441ms/step - loss: 1.4311 - categorical_accuracy: 0.3234 - val_loss: 1.4229 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-2215_29_19.738318/model-00009-1.43109-0.32338-1.42294-0.31000.h5\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 29s 432ms/step - loss: 1.3978 - categorical_accuracy: 0.3532 - val_loss: 1.4013 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-2215_29_19.738318/model-00010-1.39779-0.35323-1.40126-0.34000.h5\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 29s 440ms/step - loss: 1.4298 - categorical_accuracy: 0.3433 - val_loss: 1.3971 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-2215_29_19.738318/model-00011-1.42978-0.34328-1.39708-0.32000.h5\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 29s 435ms/step - loss: 1.3836 - categorical_accuracy: 0.3682 - val_loss: 1.3761 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-2215_29_19.738318/model-00012-1.38359-0.36816-1.37605-0.41000.h5\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 29s 440ms/step - loss: 1.4033 - categorical_accuracy: 0.3731 - val_loss: 1.3881 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-2215_29_19.738318/model-00013-1.40332-0.37313-1.38809-0.32000.h5\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 29s 438ms/step - loss: 1.3028 - categorical_accuracy: 0.4428 - val_loss: 1.3310 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-2215_29_19.738318/model-00014-1.30283-0.44279-1.33100-0.42000.h5\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 29s 435ms/step - loss: 1.3202 - categorical_accuracy: 0.4677 - val_loss: 1.3422 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-2215_29_19.738318/model-00015-1.32023-0.46766-1.34217-0.36000.h5\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 29s 434ms/step - loss: 1.2728 - categorical_accuracy: 0.4328 - val_loss: 1.2857 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-2215_29_19.738318/model-00016-1.27282-0.43284-1.28567-0.43000.h5\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 29s 428ms/step - loss: 1.3426 - categorical_accuracy: 0.4080 - val_loss: 1.2594 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-2215_29_19.738318/model-00017-1.34257-0.40796-1.25936-0.52000.h5\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 29s 437ms/step - loss: 1.2118 - categorical_accuracy: 0.5274 - val_loss: 1.2052 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-2215_29_19.738318/model-00018-1.21176-0.52736-1.20523-0.55000.h5\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 29s 434ms/step - loss: 1.2754 - categorical_accuracy: 0.4577 - val_loss: 1.1912 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-2215_29_19.738318/model-00019-1.27539-0.45771-1.19123-0.52000.h5\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 30s 441ms/step - loss: 1.0790 - categorical_accuracy: 0.5771 - val_loss: 1.0903 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-2215_29_19.738318/model-00020-1.07904-0.57711-1.09027-0.60000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd75bcf2f28>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp :5- Model 2 with same number of frames,image width,image height values Changing Batch size  to 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, 30)\n",
    "val_generator = generator(val_path, val_doc, 30)\n",
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ./Project_data/val ; batch size = 30\n",
      "Source path =  ./Project_data/train ; batch size = 30\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/21 [>.............................] - ETA: 4:46 - loss: 1.6094 - categorical_accuracy: 0.2333Batch:  4 Index: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 73s 3s/step - loss: 1.7201 - categorical_accuracy: 0.2238 - val_loss: 1.6021 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2216_44_36.385184/model-00001-1.72011-0.22381-1.60207-0.32000.h5\n",
      "Epoch 2/10\n",
      "Batch:  23 Index: 30\n",
      "21/21 [==============================] - 9s 437ms/step - loss: 1.6036 - categorical_accuracy: 0.2530 - val_loss: 1.5997 - val_categorical_accuracy: 0.1750\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2216_44_36.385184/model-00002-1.60301-0.26667-1.59966-0.17500.h5\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 8s 378ms/step - loss: 1.6344 - categorical_accuracy: 0.1111 - val_loss: 1.6084 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2216_44_36.385184/model-00003-1.63442-0.11111-1.60843-0.25000.h5\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 7s 341ms/step - loss: 1.6097 - categorical_accuracy: 0.2063 - val_loss: 1.6113 - val_categorical_accuracy: 0.1250\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2216_44_36.385184/model-00004-1.60972-0.20635-1.61127-0.12500.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 8s 378ms/step - loss: 1.6076 - categorical_accuracy: 0.2381 - val_loss: 1.6106 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2216_44_36.385184/model-00005-1.60760-0.23810-1.61057-0.20000.h5\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 8s 391ms/step - loss: 1.6102 - categorical_accuracy: 0.1429 - val_loss: 1.6088 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2216_44_36.385184/model-00006-1.61025-0.14286-1.60881-0.25000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 8s 369ms/step - loss: 1.6113 - categorical_accuracy: 0.1746 - val_loss: 1.6074 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2216_44_36.385184/model-00007-1.61133-0.17460-1.60742-0.20000.h5\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 8s 371ms/step - loss: 1.6101 - categorical_accuracy: 0.1270 - val_loss: 1.6129 - val_categorical_accuracy: 0.1750\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2216_44_36.385184/model-00008-1.61008-0.12698-1.61293-0.17500.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 8s 367ms/step - loss: 1.6076 - categorical_accuracy: 0.3175 - val_loss: 1.6033 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-2216_44_36.385184/model-00009-1.60760-0.31746-1.60334-0.30000.h5\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 7s 333ms/step - loss: 1.6097 - categorical_accuracy: 0.1587 - val_loss: 1.6129 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-2216_44_36.385184/model-00010-1.60966-0.15873-1.61287-0.15000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bc3b986a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp :6- Model 2 with same number of frames,image width,image height values Changing Batch size  to 40 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, 40)\n",
    "val_generator = generator(val_path, val_doc, 40)\n",
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ./Project_data/val ; batch size = 40\n",
      "Source path =  ./Project_data/train ; batch size = 40\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/21 [>.............................] - ETA: 3:31 - loss: 1.6081 - categorical_accuracy: 0.1750Batch:  3 Index: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/21 [====================>.........] - ETA: 27s - loss: 1.6089 - categorical_accuracy: 0.2100Batch:  17 Index: 40\n",
      "21/21 [==============================] - 86s 4s/step - loss: 1.6091 - categorical_accuracy: 0.2072 - val_loss: 1.6077 - val_categorical_accuracy: 0.2417\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2216_44_36.385184/model-00001-1.60899-0.20795-1.60772-0.24167.h5\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 51s 2s/step - loss: 1.6090 - categorical_accuracy: 0.2050 - val_loss: 1.6094 - val_categorical_accuracy: 0.1875\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2216_44_36.385184/model-00002-1.60896-0.20497-1.60944-0.18750.h5\n",
      "Epoch 3/10\n",
      " 2/21 [=>............................] - ETA: 43s - loss: 1.6099 - categorical_accuracy: 0.1957Batch:  29 Index: 23\n",
      "21/21 [==============================] - 43s 2s/step - loss: 1.6087 - categorical_accuracy: 0.2082 - val_loss: 1.6093 - val_categorical_accuracy: 0.2125\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2216_44_36.385184/model-00003-1.60874-0.20681-1.60931-0.21250.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 4/10\n",
      "16/21 [=====================>........] - ETA: 9s - loss: 1.6091 - categorical_accuracy: 0.2039 Batch:  35 Index: 19\n",
      "21/21 [==============================] - 40s 2s/step - loss: 1.6097 - categorical_accuracy: 0.1996 - val_loss: 1.6085 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2216_44_36.385184/model-00004-1.60965-0.19949-1.60850-0.20000.h5\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 39s 2s/step - loss: 1.6094 - categorical_accuracy: 0.1933 - val_loss: 1.6082 - val_categorical_accuracy: 0.2125\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2216_44_36.385184/model-00005-1.60941-0.19328-1.60822-0.21250.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 39s 2s/step - loss: 1.6077 - categorical_accuracy: 0.2269 - val_loss: 1.6093 - val_categorical_accuracy: 0.2250\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2216_44_36.385184/model-00006-1.60767-0.22689-1.60930-0.22500.h5\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 38s 2s/step - loss: 1.6097 - categorical_accuracy: 0.1933 - val_loss: 1.6094 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2216_44_36.385184/model-00007-1.60972-0.19328-1.60938-0.20000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 37s 2s/step - loss: 1.6079 - categorical_accuracy: 0.2185 - val_loss: 1.6072 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2216_44_36.385184/model-00008-1.60791-0.21849-1.60722-0.25000.h5\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 36s 2s/step - loss: 1.6091 - categorical_accuracy: 0.1877 - val_loss: 1.6109 - val_categorical_accuracy: 0.1750\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-2216_44_36.385184/model-00009-1.60912-0.18768-1.61088-0.17500.h5\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 39s 2s/step - loss: 1.6093 - categorical_accuracy: 0.1989 - val_loss: 1.6086 - val_categorical_accuracy: 0.2125\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-2216_44_36.385184/model-00010-1.60934-0.19888-1.60858-0.21250.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bc3b987f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp :7- Model 2 with same number of frames,image width,image height values but Change Optimizer to Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 60, 60, 32)    2624      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 30, 60, 60, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 10, 20, 20, 32)    0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 20, 20, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 10, 20, 20, 64)    55360     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 10, 20, 20, 64)    110656    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 4, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               6423040   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 6,621,925\n",
      "Trainable params: 6,621,925\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, 40)\n",
    "val_generator = generator(val_path, val_doc, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path = Source path =   ./Project_data/val./Project_data/train ; batch size = 40\n",
      "Epoch 1/10\n",
      " ; batch size = 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/21 [>.............................] - ETA: 2:39 - loss: 1.6069 - categorical_accuracy: 0.2000Batch:  3 Index: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/21 [====================>.........] - ETA: 26s - loss: 1.6097 - categorical_accuracy: 0.1917Batch:  17 Index: 40\n",
      "21/21 [==============================] - 83s 4s/step - loss: 1.6101 - categorical_accuracy: 0.1826 - val_loss: 1.6089 - val_categorical_accuracy: 0.2417\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2216_44_36.385184/model-00001-1.60988-0.18543-1.60890-0.24167.h5\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.6074 - categorical_accuracy: 0.2277 - val_loss: 1.6092 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2216_44_36.385184/model-00002-1.60736-0.22774-1.60916-0.20000.h5\n",
      "Epoch 3/10\n",
      " 2/21 [=>............................] - ETA: 43s - loss: 1.6200 - categorical_accuracy: 0.1087Batch:  29 Index: 23\n",
      "21/21 [==============================] - 43s 2s/step - loss: 1.6120 - categorical_accuracy: 0.1957 - val_loss: 1.6079 - val_categorical_accuracy: 0.2250\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2216_44_36.385184/model-00003-1.61231-0.19221-1.60789-0.22500.h5\n",
      "Epoch 4/10\n",
      "16/21 [=====================>........] - ETA: 9s - loss: 1.6098 - categorical_accuracy: 0.1908 Batch:  35 Index: 19\n",
      "21/21 [==============================] - 42s 2s/step - loss: 1.6122 - categorical_accuracy: 0.1868 - val_loss: 1.6055 - val_categorical_accuracy: 0.2625\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2216_44_36.385184/model-00004-1.61198-0.18670-1.60546-0.26250.h5\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 38s 2s/step - loss: 1.6066 - categorical_accuracy: 0.2437 - val_loss: 1.5512 - val_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2216_44_36.385184/model-00005-1.60664-0.24370-1.55122-0.37500.h5\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 38s 2s/step - loss: 1.5288 - categorical_accuracy: 0.3249 - val_loss: 1.5383 - val_categorical_accuracy: 0.3375\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2216_44_36.385184/model-00006-1.52882-0.32493-1.53831-0.33750.h5\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 39s 2s/step - loss: 1.5761 - categorical_accuracy: 0.2885 - val_loss: 1.4805 - val_categorical_accuracy: 0.3625\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2216_44_36.385184/model-00007-1.57607-0.28852-1.48045-0.36250.h5\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 38s 2s/step - loss: 1.4742 - categorical_accuracy: 0.4118 - val_loss: 1.4448 - val_categorical_accuracy: 0.3875\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2216_44_36.385184/model-00008-1.47420-0.41176-1.44479-0.38750.h5\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 38s 2s/step - loss: 1.4543 - categorical_accuracy: 0.3445 - val_loss: 1.4007 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-2216_44_36.385184/model-00009-1.45430-0.34454-1.40066-0.40000.h5\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 36s 2s/step - loss: 1.4066 - categorical_accuracy: 0.4146 - val_loss: 1.5454 - val_categorical_accuracy: 0.2750\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-2216_44_36.385184/model-00010-1.40658-0.41457-1.54544-0.27500.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bc337ae48>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp :8- Model 3 with Change back number of frames,image width,image height values to (30,120,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing back batch size, images per frame, height and width of image\n",
    "batch_size = 10\n",
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120# image height\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_13 (Conv3D)           (None, 30, 120, 120, 32)  2624      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 30, 120, 120, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_14 (Conv3D)           (None, 30, 120, 120, 32)  27680     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 30, 120, 120, 32)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 10, 40, 40, 64)    55360     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 10, 40, 40, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_16 (Conv3D)           (None, 10, 40, 40, 64)    110656    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10, 40, 40, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 4, 14, 14, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4, 14, 14, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_17 (Conv3D)           (None, 4, 14, 14, 64)     110656    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 4, 14, 14, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_18 (Conv3D)           (None, 4, 14, 14, 64)     110656    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 4, 14, 14, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 2, 5, 5, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 2, 5, 5, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               1638912   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 2,061,157\n",
      "Trainable params: 2,060,133\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Conv3D(32, kernel_size=(3, 3, 3), input_shape=(x,y,z,n_channel), padding=\"same\"))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(Conv3D(32, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "model_3.add(Dropout(0.25))\n",
    "\n",
    "model_3.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "model_3.add(Dropout(0.25))\n",
    "\n",
    "model_3.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "model_3.add(Dropout(0.25))\n",
    "\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(512, activation='relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Dropout(0.5))\n",
    "model_3.add(Dense(n_classes, activation='softmax'))\n",
    "model_3.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ./Project_data/val ; batch size = 10\n",
      "Source path =  ./Project_data/train ; batch size = 10\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/67 [========================>.....] - ETA: 20s - loss: 2.1865 - categorical_accuracy: 0.3071Batch:  67 Index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 127s 2s/step - loss: 2.1501 - categorical_accuracy: 0.3039 - val_loss: 4.3592 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2115_12_34.066620/model-00001-2.16010-0.30015-4.35920-0.32000.h5\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 47s 706ms/step - loss: 2.1513 - categorical_accuracy: 0.2388 - val_loss: 2.3216 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2115_12_34.066620/model-00002-2.15131-0.23881-2.32159-0.24000.h5\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 47s 703ms/step - loss: 1.9491 - categorical_accuracy: 0.2786 - val_loss: 2.3894 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2115_12_34.066620/model-00003-1.94913-0.27861-2.38944-0.27000.h5\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 47s 704ms/step - loss: 1.8350 - categorical_accuracy: 0.2886 - val_loss: 1.4254 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2115_12_34.066620/model-00004-1.83501-0.28856-1.42541-0.44000.h5\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 47s 703ms/step - loss: 1.7690 - categorical_accuracy: 0.3085 - val_loss: 3.3707 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2115_12_34.066620/model-00005-1.76899-0.30846-3.37068-0.32000.h5\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 47s 703ms/step - loss: 1.8669 - categorical_accuracy: 0.2587 - val_loss: 1.8284 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2115_12_34.066620/model-00006-1.86690-0.25871-1.82844-0.35000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 47s 704ms/step - loss: 1.7800 - categorical_accuracy: 0.2488 - val_loss: 1.5412 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2115_12_34.066620/model-00007-1.78001-0.24876-1.54124-0.45000.h5\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 47s 704ms/step - loss: 1.7253 - categorical_accuracy: 0.2687 - val_loss: 1.5405 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2115_12_34.066620/model-00008-1.72534-0.26866-1.54051-0.44000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.25.\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 47s 704ms/step - loss: 1.6658 - categorical_accuracy: 0.2836 - val_loss: 1.3746 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-2115_12_34.066620/model-00009-1.66578-0.28358-1.37458-0.31000.h5\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 47s 703ms/step - loss: 1.4929 - categorical_accuracy: 0.4179 - val_loss: 1.3994 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-2115_12_34.066620/model-00010-1.49293-0.41791-1.39940-0.33000.h5\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 47s 702ms/step - loss: 1.7046 - categorical_accuracy: 0.2736 - val_loss: 1.3922 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-2115_12_34.066620/model-00011-1.70461-0.27363-1.39224-0.39000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.125.\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 47s 702ms/step - loss: 1.5627 - categorical_accuracy: 0.3682 - val_loss: 1.3817 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-2115_12_34.066620/model-00012-1.56267-0.36816-1.38172-0.36000.h5\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 47s 702ms/step - loss: 1.6282 - categorical_accuracy: 0.3134 - val_loss: 1.4005 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-2115_12_34.066620/model-00013-1.62822-0.31343-1.40050-0.36000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0625.\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 47s 704ms/step - loss: 1.6423 - categorical_accuracy: 0.3085 - val_loss: 1.3994 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-2115_12_34.066620/model-00014-1.64231-0.30846-1.39940-0.37000.h5\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 47s 706ms/step - loss: 1.7030 - categorical_accuracy: 0.3284 - val_loss: 1.4038 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-2115_12_34.066620/model-00015-1.70301-0.32836-1.40383-0.39000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.03125.\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 47s 706ms/step - loss: 1.6098 - categorical_accuracy: 0.3184 - val_loss: 1.4003 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-2115_12_34.066620/model-00016-1.60983-0.31841-1.40029-0.40000.h5\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 47s 705ms/step - loss: 1.6064 - categorical_accuracy: 0.3582 - val_loss: 1.4102 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-2115_12_34.066620/model-00017-1.60638-0.35821-1.41016-0.38000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.015625.\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 47s 707ms/step - loss: 1.5160 - categorical_accuracy: 0.3383 - val_loss: 1.4170 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-2115_12_34.066620/model-00018-1.51602-0.33831-1.41699-0.39000.h5\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 47s 706ms/step - loss: 1.6092 - categorical_accuracy: 0.3134 - val_loss: 1.4143 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-2115_12_34.066620/model-00019-1.60921-0.31343-1.41431-0.39000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0078125.\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 47s 705ms/step - loss: 1.5088 - categorical_accuracy: 0.3532 - val_loss: 1.3905 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-2115_12_34.066620/model-00020-1.50876-0.35323-1.39055-0.38000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4456a2a588>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp :9- Model 4 with same number of frames,image width,image height values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_19 (Conv3D)           (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_12 (MaxPooling (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_20 (Conv3D)           (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_13 (MaxPooling (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_21 (Conv3D)           (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_14 (MaxPooling (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_22 (Conv3D)           (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 3, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_15 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1000)              3137000   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 3,667,749\n",
      "Trainable params: 3,667,509\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=(x,y,z,n_channel)\n",
    "\n",
    "nb_filters = [8,16,32,64]\n",
    "nb_dense = [1000, 500, 5]\n",
    "# Define model\n",
    "model_4 = Sequential()\n",
    "\n",
    "model_4.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Activation('relu'))\n",
    "\n",
    "model_4.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_4.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Activation('relu'))\n",
    "\n",
    "model_4.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_4.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Activation('relu'))\n",
    "\n",
    "model_4.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_4.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Activation('relu'))\n",
    "\n",
    "model_4.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model_4.add(Flatten())\n",
    "\n",
    "model_4.add(Dense(nb_dense[0], activation='relu'))\n",
    "model_4.add(Dropout(0.5))\n",
    "\n",
    "model_4.add(Dense(nb_dense[1], activation='relu'))\n",
    "model_4.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model_4.add(Dense(nb_dense[2], activation='softmax'))\n",
    "model_4.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ./Project_data/val ; batch size = 10\n",
      "Source path =  ./Project_data/train ; batch size =Epoch 1/10\n",
      " 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/67 [============================>.] - ETA: 2s - loss: 5.7044 - categorical_accuracy: 0.2523Batch:  67 Index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 79s 1s/step - loss: 5.6102 - categorical_accuracy: 0.2493 - val_loss: 2.6864 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2115_12_34.066620/model-00001-5.64189-0.25189-2.68638-0.28000.h5\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 2.5352 - categorical_accuracy: 0.3184 - val_loss: 1.6390 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2115_12_34.066620/model-00002-2.53516-0.31841-1.63904-0.36000.h5\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 1.9549 - categorical_accuracy: 0.2637 - val_loss: 1.3116 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2115_12_34.066620/model-00003-1.95494-0.26368-1.31159-0.44000.h5\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 25s 373ms/step - loss: 1.7522 - categorical_accuracy: 0.2985 - val_loss: 1.2079 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2115_12_34.066620/model-00004-1.75220-0.29851-1.20794-0.50000.h5\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 26s 389ms/step - loss: 1.5682 - categorical_accuracy: 0.3582 - val_loss: 1.3952 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2115_12_34.066620/model-00005-1.56817-0.35821-1.39523-0.38000.h5\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 26s 389ms/step - loss: 1.6138 - categorical_accuracy: 0.3284 - val_loss: 1.3586 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2115_12_34.066620/model-00006-1.61378-0.32836-1.35863-0.48000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 25s 377ms/step - loss: 1.4965 - categorical_accuracy: 0.3383 - val_loss: 1.1054 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2115_12_34.066620/model-00007-1.49646-0.33831-1.10540-0.56000.h5\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 26s 392ms/step - loss: 1.3075 - categorical_accuracy: 0.4478 - val_loss: 1.1187 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2115_12_34.066620/model-00008-1.30751-0.44776-1.11872-0.51000.h5\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 26s 384ms/step - loss: 1.3812 - categorical_accuracy: 0.3881 - val_loss: 1.1215 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-2115_12_34.066620/model-00009-1.38118-0.38806-1.12153-0.54000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.25.\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 26s 382ms/step - loss: 1.2542 - categorical_accuracy: 0.4527 - val_loss: 1.0886 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-2115_12_34.066620/model-00010-1.25424-0.45274-1.08859-0.60000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4455d1b7f0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)\n",
    "num_epochs = 10\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "    \n",
    "model_4.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp :10- Model 5 with Changing number of frames,image width,image height values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 30 # number of frames\n",
    "y = 64 # image width\n",
    "z = 64 # image height \n",
    "\n",
    "n_classes = 5\n",
    "n_channel = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_23 (Conv3D)           (None, 30, 64, 64, 32)    2624      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 30, 64, 64, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_24 (Conv3D)           (None, 30, 64, 64, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 30, 64, 64, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_16 (MaxPooling (None, 10, 22, 22, 32)    0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 10, 22, 22, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_25 (Conv3D)           (None, 10, 22, 22, 64)    55360     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 10, 22, 22, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_26 (Conv3D)           (None, 10, 22, 22, 64)    110656    \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 10, 22, 22, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_17 (MaxPooling (None, 4, 8, 8, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 4, 8, 8, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_27 (Conv3D)           (None, 4, 8, 8, 64)       110656    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 4, 8, 8, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_28 (Conv3D)           (None, 4, 8, 8, 64)       110656    \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 4, 8, 8, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_18 (MaxPooling (None, 2, 3, 3, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 2, 3, 3, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 1,012,581\n",
      "Trainable params: 1,011,557\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5 = Sequential()\n",
    "model_5.add(Conv3D(32, kernel_size=(3, 3, 3), input_shape=(x,y,z,n_channel), padding=\"same\"))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(Conv3D(32, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "model_5.add(Dropout(0.25))\n",
    "\n",
    "model_5.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "model_5.add(Dropout(0.25))\n",
    "\n",
    "model_5.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "model_5.add(Dropout(0.25))\n",
    "\n",
    "model_5.add(Flatten())\n",
    "model_5.add(Dense(512, activation='relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Dropout(0.5))\n",
    "model_5.add(Dense(n_classes, activation='softmax'))\n",
    "model_5.compile(optimizer=optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/34 [===========================>..] - ETA: 4s - loss: 2.1559 - categorical_accuracy: 0.2844Batch:  34 Index: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 75s 2s/step - loss: 2.1077 - categorical_accuracy: 0.3017 - val_loss: 1.6028 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2115_12_34.066620/model-00001-2.14180-0.29261-1.60282-0.37000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 10s 297ms/step - loss: 2.2930 - categorical_accuracy: 0.1961 - val_loss: 7.3864 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2115_12_34.066620/model-00002-2.29299-0.19608-7.38641-0.23000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 13s 383ms/step - loss: 2.2068 - categorical_accuracy: 0.2451 - val_loss: 6.7557 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2115_12_34.066620/model-00003-2.20682-0.24510-6.75566-0.23000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 13s 373ms/step - loss: 1.9834 - categorical_accuracy: 0.2843 - val_loss: 2.6452 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2115_12_34.066620/model-00004-1.98345-0.28431-2.64521-0.25000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 13s 374ms/step - loss: 1.9703 - categorical_accuracy: 0.3235 - val_loss: 2.2702 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2115_12_34.066620/model-00005-1.97034-0.32353-2.27020-0.21000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.25.\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 14s 422ms/step - loss: 1.9630 - categorical_accuracy: 0.2941 - val_loss: 1.5598 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2115_12_34.066620/model-00006-1.96302-0.29412-1.55984-0.25000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 2.0786 - categorical_accuracy: 0.2647 - val_loss: 1.4755 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2115_12_34.066620/model-00007-2.07857-0.26471-1.47547-0.36000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 14s 407ms/step - loss: 1.8862 - categorical_accuracy: 0.2941 - val_loss: 1.4872 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2115_12_34.066620/model-00008-1.88620-0.29412-1.48723-0.31000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 15s 427ms/step - loss: 1.9810 - categorical_accuracy: 0.2843 - val_loss: 1.4620 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-2115_12_34.066620/model-00009-1.98095-0.28431-1.46203-0.34000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 14s 412ms/step - loss: 1.7872 - categorical_accuracy: 0.3431 - val_loss: 1.4225 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-2115_12_34.066620/model-00010-1.78715-0.34314-1.42245-0.28000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 15s 440ms/step - loss: 2.0244 - categorical_accuracy: 0.3039 - val_loss: 1.3931 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-2115_12_34.066620/model-00011-2.02441-0.30392-1.39307-0.42000.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 15s 430ms/step - loss: 2.1630 - categorical_accuracy: 0.2451 - val_loss: 1.4263 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-2115_12_34.066620/model-00012-2.16302-0.24510-1.42629-0.34000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 14s 419ms/step - loss: 1.9354 - categorical_accuracy: 0.3333 - val_loss: 1.4282 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-2115_12_34.066620/model-00013-1.93545-0.33333-1.42816-0.32000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.125.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 14s 424ms/step - loss: 1.7237 - categorical_accuracy: 0.2941 - val_loss: 1.3973 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-2115_12_34.066620/model-00014-1.72371-0.29412-1.39727-0.33000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 14s 421ms/step - loss: 1.8002 - categorical_accuracy: 0.2745 - val_loss: 1.3724 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-2115_12_34.066620/model-00015-1.80019-0.27451-1.37240-0.35000.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 14s 415ms/step - loss: 2.0834 - categorical_accuracy: 0.2059 - val_loss: 1.3702 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-2115_12_34.066620/model-00016-2.08336-0.20588-1.37018-0.39000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 14s 421ms/step - loss: 1.8279 - categorical_accuracy: 0.3137 - val_loss: 1.3674 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-2115_12_34.066620/model-00017-1.82791-0.31373-1.36744-0.43000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 14s 420ms/step - loss: 1.7934 - categorical_accuracy: 0.2941 - val_loss: 1.3444 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-2115_12_34.066620/model-00018-1.79340-0.29412-1.34439-0.39000.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 14s 420ms/step - loss: 1.7531 - categorical_accuracy: 0.3039 - val_loss: 1.3522 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-2115_12_34.066620/model-00019-1.75305-0.30392-1.35223-0.37000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 14s 420ms/step - loss: 1.6434 - categorical_accuracy: 0.3922 - val_loss: 1.3490 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-2115_12_34.066620/model-00020-1.64345-0.39216-1.34897-0.39000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0625.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4454839278>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 20\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)\n",
    "num_epochs = 20\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "    \n",
    "model_5.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp :11- Model 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_29 (Conv3D)           (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_19 (MaxPooling (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_30 (Conv3D)           (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_20 (MaxPooling (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_31 (Conv3D)           (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_21 (MaxPooling (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_32 (Conv3D)           (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 3, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_22 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1000)              3137000   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 3,667,749\n",
      "Trainable params: 3,667,509\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height \n",
    "\n",
    "n_classes = 5\n",
    "n_channel = 3\n",
    "nb_filters = [8,16,32,64]\n",
    "nb_dense = [1000, 500, 5]\n",
    "\n",
    "input_shape=(x,y,z,n_channel)\n",
    "\n",
    "# Define model\n",
    "model_6 = Sequential()\n",
    "\n",
    "model_6.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(Activation('relu'))\n",
    "\n",
    "model_6.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_6.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(Activation('relu'))\n",
    "\n",
    "model_6.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_6.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(Activation('relu'))\n",
    "\n",
    "model_6.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_6.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(Activation('relu'))\n",
    "\n",
    "model_6.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model_6.add(Flatten())\n",
    "\n",
    "model_6.add(Dense(nb_dense[0], activation='relu'))\n",
    "model_6.add(Dropout(0.5))\n",
    "\n",
    "model_6.add(Dense(nb_dense[1], activation='relu'))\n",
    "model_6.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model_6.add(Dense(nb_dense[2], activation='softmax'))\n",
    "model_6.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ./Project_data/val ; batch size = 10\n",
      "Source path =  ./Project_data/train ; batch size = 10\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/67 [============================>.] - ETA: 2s - loss: 6.4483 - categorical_accuracy: 0.2646Batch:  67 Index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 77s 1s/step - loss: 6.3179 - categorical_accuracy: 0.2677 - val_loss: 3.0815 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2115_12_34.066620/model-00001-6.36483-0.26697-3.08149-0.31000.h5\n",
      "Epoch 2/30\n",
      "67/67 [==============================] - 22s 334ms/step - loss: 2.4801 - categorical_accuracy: 0.1940 - val_loss: 1.8449 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2115_12_34.066620/model-00002-2.48015-0.19403-1.84487-0.32000.h5\n",
      "Epoch 3/30\n",
      "67/67 [==============================] - 25s 379ms/step - loss: 1.8412 - categorical_accuracy: 0.2985 - val_loss: 1.7328 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2115_12_34.066620/model-00003-1.84117-0.29851-1.73282-0.24000.h5\n",
      "Epoch 4/30\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 1.6102 - categorical_accuracy: 0.3682 - val_loss: 1.6257 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2115_12_34.066620/model-00004-1.61021-0.36816-1.62574-0.25000.h5\n",
      "Epoch 5/30\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 1.5139 - categorical_accuracy: 0.3333 - val_loss: 1.1993 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2115_12_34.066620/model-00005-1.51390-0.33333-1.19934-0.53000.h5\n",
      "Epoch 6/30\n",
      "67/67 [==============================] - 27s 396ms/step - loss: 1.3882 - categorical_accuracy: 0.4179 - val_loss: 1.2019 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2115_12_34.066620/model-00006-1.38823-0.41791-1.20189-0.52000.h5\n",
      "Epoch 7/30\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 1.4480 - categorical_accuracy: 0.3483 - val_loss: 1.4943 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2115_12_34.066620/model-00007-1.44798-0.34826-1.49434-0.43000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "Epoch 8/30\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 1.3070 - categorical_accuracy: 0.3731 - val_loss: 1.5155 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2115_12_34.066620/model-00008-1.30696-0.37313-1.51547-0.38000.h5\n",
      "Epoch 9/30\n",
      "67/67 [==============================] - 25s 380ms/step - loss: 1.1009 - categorical_accuracy: 0.5423 - val_loss: 1.0339 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-2115_12_34.066620/model-00009-1.10088-0.54229-1.03389-0.61000.h5\n",
      "Epoch 10/30\n",
      "67/67 [==============================] - 25s 380ms/step - loss: 1.2459 - categorical_accuracy: 0.4876 - val_loss: 0.9329 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-2115_12_34.066620/model-00010-1.24587-0.48756-0.93292-0.63000.h5\n",
      "Epoch 11/30\n",
      "67/67 [==============================] - 25s 379ms/step - loss: 1.1956 - categorical_accuracy: 0.5224 - val_loss: 1.1365 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-2115_12_34.066620/model-00011-1.19557-0.52239-1.13645-0.54000.h5\n",
      "Epoch 12/30\n",
      "67/67 [==============================] - 25s 373ms/step - loss: 1.1105 - categorical_accuracy: 0.5672 - val_loss: 0.9803 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-2115_12_34.066620/model-00012-1.11046-0.56716-0.98034-0.60000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.25.\n",
      "Epoch 13/30\n",
      "67/67 [==============================] - 25s 372ms/step - loss: 0.9402 - categorical_accuracy: 0.6020 - val_loss: 0.7849 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-2115_12_34.066620/model-00013-0.94019-0.60199-0.78486-0.72000.h5\n",
      "Epoch 14/30\n",
      "67/67 [==============================] - 25s 372ms/step - loss: 0.8425 - categorical_accuracy: 0.6667 - val_loss: 0.8244 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-2115_12_34.066620/model-00014-0.84254-0.66667-0.82441-0.71000.h5\n",
      "Epoch 15/30\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.9137 - categorical_accuracy: 0.6219 - val_loss: 0.8938 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-2115_12_34.066620/model-00015-0.91365-0.62189-0.89383-0.67000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.125.\n",
      "Epoch 16/30\n",
      "67/67 [==============================] - 25s 378ms/step - loss: 0.9161 - categorical_accuracy: 0.6318 - val_loss: 0.8105 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-2115_12_34.066620/model-00016-0.91607-0.63184-0.81054-0.72000.h5\n",
      "Epoch 17/30\n",
      "67/67 [==============================] - 25s 378ms/step - loss: 0.8669 - categorical_accuracy: 0.6468 - val_loss: 0.7665 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-2115_12_34.066620/model-00017-0.86685-0.64677-0.76650-0.71000.h5\n",
      "Epoch 18/30\n",
      "67/67 [==============================] - 25s 380ms/step - loss: 0.8836 - categorical_accuracy: 0.6318 - val_loss: 0.7807 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-2115_12_34.066620/model-00018-0.88362-0.63184-0.78074-0.70000.h5\n",
      "Epoch 19/30\n",
      "67/67 [==============================] - 26s 381ms/step - loss: 0.7959 - categorical_accuracy: 0.6667 - val_loss: 0.7604 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-2115_12_34.066620/model-00019-0.79593-0.66667-0.76041-0.73000.h5\n",
      "Epoch 20/30\n",
      "67/67 [==============================] - 26s 390ms/step - loss: 0.8151 - categorical_accuracy: 0.6517 - val_loss: 0.6991 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-2115_12_34.066620/model-00020-0.81513-0.65174-0.69905-0.77000.h5\n",
      "Epoch 21/30\n",
      "67/67 [==============================] - 25s 374ms/step - loss: 0.6861 - categorical_accuracy: 0.7214 - val_loss: 0.7278 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00021: saving model to model_init_2019-09-2115_12_34.066620/model-00021-0.68610-0.72139-0.72783-0.72000.h5\n",
      "Epoch 22/30\n",
      "67/67 [==============================] - 25s 374ms/step - loss: 0.8816 - categorical_accuracy: 0.6468 - val_loss: 0.7091 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00022: saving model to model_init_2019-09-2115_12_34.066620/model-00022-0.88158-0.64677-0.70911-0.72000.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0625.\n",
      "Epoch 23/30\n",
      "67/67 [==============================] - 25s 381ms/step - loss: 0.7788 - categorical_accuracy: 0.7015 - val_loss: 0.7223 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00023: saving model to model_init_2019-09-2115_12_34.066620/model-00023-0.77882-0.70149-0.72231-0.77000.h5\n",
      "Epoch 24/30\n",
      "67/67 [==============================] - 26s 392ms/step - loss: 0.7842 - categorical_accuracy: 0.7015 - val_loss: 0.6913 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00024: saving model to model_init_2019-09-2115_12_34.066620/model-00024-0.78423-0.70149-0.69132-0.74000.h5\n",
      "Epoch 25/30\n",
      "67/67 [==============================] - 26s 388ms/step - loss: 0.7174 - categorical_accuracy: 0.6915 - val_loss: 0.6770 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00025: saving model to model_init_2019-09-2115_12_34.066620/model-00025-0.71740-0.69154-0.67703-0.76000.h5\n",
      "Epoch 26/30\n",
      "67/67 [==============================] - 26s 392ms/step - loss: 0.7854 - categorical_accuracy: 0.6866 - val_loss: 0.6929 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00026: saving model to model_init_2019-09-2115_12_34.066620/model-00026-0.78540-0.68657-0.69289-0.75000.h5\n",
      "Epoch 27/30\n",
      "67/67 [==============================] - 25s 374ms/step - loss: 0.6478 - categorical_accuracy: 0.7413 - val_loss: 0.6924 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00027: saving model to model_init_2019-09-2115_12_34.066620/model-00027-0.64779-0.74129-0.69240-0.77000.h5\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.03125.\n",
      "Epoch 28/30\n",
      "67/67 [==============================] - 26s 388ms/step - loss: 0.6898 - categorical_accuracy: 0.7065 - val_loss: 0.6721 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00028: saving model to model_init_2019-09-2115_12_34.066620/model-00028-0.68984-0.70647-0.67211-0.76000.h5\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 24s 354ms/step - loss: 0.7085 - categorical_accuracy: 0.7015 - val_loss: 0.6650 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00029: saving model to model_init_2019-09-2115_12_34.066620/model-00029-0.70849-0.70149-0.66503-0.76000.h5\n",
      "Epoch 30/30\n",
      "67/67 [==============================] - 25s 374ms/step - loss: 0.6580 - categorical_accuracy: 0.7214 - val_loss: 0.6604 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00030: saving model to model_init_2019-09-2115_12_34.066620/model-00030-0.65798-0.72139-0.66042-0.77000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4453a71630>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)\n",
    "num_epochs = 30\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "model_6.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model - Conv3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_filters = [8,16,32,64]\n",
    "#n_dense = [256, 128, 5]\n",
    "\n",
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height \n",
    "\n",
    "n_classes = 5\n",
    "n_channel = 3\n",
    "\n",
    "# Input\n",
    "input_shape=(x,y,z,n_channel)\n",
    "\n",
    "# Define model\n",
    "model_f = Sequential()\n",
    "\n",
    "model_f.add(Conv3D(8, \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model_f.add(BatchNormalization())\n",
    "model_f.add(Activation('relu'))\n",
    "\n",
    "model_f.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_f.add(Conv3D(16, \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model_f.add(BatchNormalization())\n",
    "model_f.add(Activation('relu'))\n",
    "\n",
    "model_f.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_f.add(Conv3D(32, \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_f.add(BatchNormalization())\n",
    "model_f.add(Activation('relu'))\n",
    "\n",
    "model_f.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_f.add(Conv3D(64, \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_f.add(Activation('relu'))\n",
    "model_f.add(Dropout(0.25))\n",
    "\n",
    "model_f.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model_f.add(Flatten())\n",
    "\n",
    "model_f.add(Dense(256, activation='relu'))\n",
    "model_f.add(Dropout(0.5))\n",
    "\n",
    "model_f.add(Dense(128, activation='relu'))\n",
    "model_f.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model_f.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_5 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 864,101\n",
      "Trainable params: 863,989\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model_f.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_f.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ./Project_data/val ; batch size = 10\n",
      "Source path =  ./Project_data/train ; batch size = 10\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/67 [============================>.] - ETA: 2s - loss: 1.9930 - categorical_accuracy: 0.2523Batch:  67 Index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 84s 1s/step - loss: 1.9784 - categorical_accuracy: 0.2587 - val_loss: 1.4354 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2216_44_36.385184/model-00001-1.98052-0.25792-1.43541-0.29000.h5\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 1.6124 - categorical_accuracy: 0.2338 - val_loss: 1.5106 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2216_44_36.385184/model-00002-1.61238-0.23383-1.51060-0.20000.h5\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 26s 394ms/step - loss: 1.5303 - categorical_accuracy: 0.2935 - val_loss: 1.4576 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2216_44_36.385184/model-00003-1.53030-0.29353-1.45758-0.26000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 1.5352 - categorical_accuracy: 0.3035 - val_loss: 1.3889 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2216_44_36.385184/model-00004-1.53522-0.30348-1.38893-0.33000.h5\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 1.4045 - categorical_accuracy: 0.3881 - val_loss: 1.2282 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2216_44_36.385184/model-00005-1.40445-0.38806-1.22819-0.53000.h5\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 26s 386ms/step - loss: 1.4446 - categorical_accuracy: 0.3682 - val_loss: 1.3204 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2216_44_36.385184/model-00006-1.44462-0.36816-1.32041-0.44000.h5\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 27s 410ms/step - loss: 1.3178 - categorical_accuracy: 0.4328 - val_loss: 1.3954 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2216_44_36.385184/model-00007-1.31777-0.43284-1.39543-0.35000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 1.3070 - categorical_accuracy: 0.4527 - val_loss: 1.2735 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2216_44_36.385184/model-00008-1.30699-0.45274-1.27349-0.50000.h5\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 26s 392ms/step - loss: 1.2999 - categorical_accuracy: 0.4826 - val_loss: 1.1190 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-2216_44_36.385184/model-00009-1.29992-0.48259-1.11905-0.60000.h5\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 1.1638 - categorical_accuracy: 0.4975 - val_loss: 1.0712 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-2216_44_36.385184/model-00010-1.16382-0.49751-1.07124-0.63000.h5\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 27s 402ms/step - loss: 1.1345 - categorical_accuracy: 0.5274 - val_loss: 1.0355 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-2216_44_36.385184/model-00011-1.13454-0.52736-1.03553-0.62000.h5\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 26s 384ms/step - loss: 1.0604 - categorical_accuracy: 0.6020 - val_loss: 0.9286 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-2216_44_36.385184/model-00012-1.06039-0.60199-0.92863-0.67000.h5\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 27s 410ms/step - loss: 0.9699 - categorical_accuracy: 0.6269 - val_loss: 1.0211 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-2216_44_36.385184/model-00013-0.96993-0.62687-1.02115-0.65000.h5\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 26s 384ms/step - loss: 1.0859 - categorical_accuracy: 0.5522 - val_loss: 0.8988 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-2216_44_36.385184/model-00014-1.08591-0.55224-0.89878-0.72000.h5\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 28s 415ms/step - loss: 0.9367 - categorical_accuracy: 0.6070 - val_loss: 0.8837 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-2216_44_36.385184/model-00015-0.93674-0.60697-0.88367-0.66000.h5\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 27s 403ms/step - loss: 0.9236 - categorical_accuracy: 0.6418 - val_loss: 0.8540 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-2216_44_36.385184/model-00016-0.92360-0.64179-0.85404-0.76000.h5\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.8973 - categorical_accuracy: 0.5920 - val_loss: 0.8843 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-2216_44_36.385184/model-00017-0.89729-0.59204-0.88433-0.73000.h5\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 28s 414ms/step - loss: 0.8390 - categorical_accuracy: 0.6667 - val_loss: 0.9147 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-2216_44_36.385184/model-00018-0.83898-0.66667-0.91470-0.70000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 0.8656 - categorical_accuracy: 0.6318 - val_loss: 0.8529 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-2216_44_36.385184/model-00019-0.86556-0.63184-0.85289-0.72000.h5\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 26s 388ms/step - loss: 0.7659 - categorical_accuracy: 0.6965 - val_loss: 0.8075 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-2216_44_36.385184/model-00020-0.76591-0.69652-0.80754-0.75000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bb34e3780>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_epochs = 20\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "model_f.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ./Project_data/val ; batch size = 32\n",
      "Source path =  Epoch 1/20\n",
      "./Project_data/train ; batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/21 [===>..........................] - ETA: 1:23 - loss: 0.5692 - categorical_accuracy: 0.8438Batch:  4 Index: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/21 [==========================>...] - ETA: 7s - loss: 0.6346 - categorical_accuracy: 0.7533 Batch:  21 Index: 32\n",
      "21/21 [==============================] - 84s 4s/step - loss: 0.6513 - categorical_accuracy: 0.7415 - val_loss: 0.8022 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2216_44_36.385184/model-00001-0.65006-0.74208-0.80216-0.73000.h5\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.6524 - categorical_accuracy: 0.7433 - val_loss: 0.6856 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2216_44_36.385184/model-00002-0.65245-0.74327-0.68560-0.75000.h5\n",
      "Epoch 3/20\n",
      " 6/21 [=======>......................] - ETA: 38s - loss: 0.5699 - categorical_accuracy: 0.7899Batch:  29 Index: 23\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.6047 - categorical_accuracy: 0.7697 - val_loss: 0.8409 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2216_44_36.385184/model-00003-0.60392-0.77049-0.84092-0.62500.h5\n",
      "Epoch 4/20\n",
      "20/21 [===========================>..] - ETA: 2s - loss: 0.6116 - categorical_accuracy: 0.7816Batch:  35 Index: 19\n",
      "21/21 [==============================] - 46s 2s/step - loss: 0.6052 - categorical_accuracy: 0.7870 - val_loss: 0.6090 - val_categorical_accuracy: 0.8125\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2216_44_36.385184/model-00004-0.60518-0.78697-0.60898-0.81250.h5\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - 41s 2s/step - loss: 0.6190 - categorical_accuracy: 0.7675 - val_loss: 0.6413 - val_categorical_accuracy: 0.8750\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2216_44_36.385184/model-00005-0.61896-0.76751-0.64129-0.87500.h5\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - 43s 2s/step - loss: 0.5332 - categorical_accuracy: 0.7899 - val_loss: 0.8467 - val_categorical_accuracy: 0.6875\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2216_44_36.385184/model-00006-0.53320-0.78992-0.84667-0.68750.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - 40s 2s/step - loss: 0.5951 - categorical_accuracy: 0.7563 - val_loss: 0.8474 - val_categorical_accuracy: 0.8125\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2216_44_36.385184/model-00007-0.59513-0.75630-0.84737-0.81250.h5\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - 44s 2s/step - loss: 0.5928 - categorical_accuracy: 0.7423 - val_loss: 0.8348 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2216_44_36.385184/model-00008-0.59275-0.74230-0.83482-0.75000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - 43s 2s/step - loss: 0.5913 - categorical_accuracy: 0.7647 - val_loss: 0.6625 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-2216_44_36.385184/model-00009-0.59130-0.76471-0.66246-0.75000.h5\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - 41s 2s/step - loss: 0.5831 - categorical_accuracy: 0.7731 - val_loss: 0.9570 - val_categorical_accuracy: 0.6875\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-2216_44_36.385184/model-00010-0.58310-0.77311-0.95697-0.68750.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - 42s 2s/step - loss: 0.5695 - categorical_accuracy: 0.7871 - val_loss: 0.5712 - val_categorical_accuracy: 0.8750\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-2216_44_36.385184/model-00011-0.56951-0.78711-0.57122-0.87500.h5\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - 42s 2s/step - loss: 0.5853 - categorical_accuracy: 0.7619 - val_loss: 0.5685 - val_categorical_accuracy: 0.8750\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-2216_44_36.385184/model-00012-0.58526-0.76190-0.56847-0.87500.h5\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - 42s 2s/step - loss: 0.5712 - categorical_accuracy: 0.7731 - val_loss: 0.8801 - val_categorical_accuracy: 0.6875\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-2216_44_36.385184/model-00013-0.57116-0.77311-0.88013-0.68750.h5\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - 40s 2s/step - loss: 0.6001 - categorical_accuracy: 0.7675 - val_loss: 0.6608 - val_categorical_accuracy: 0.8125\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-2216_44_36.385184/model-00014-0.60009-0.76751-0.66085-0.81250.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - 44s 2s/step - loss: 0.5618 - categorical_accuracy: 0.7871 - val_loss: 0.9840 - val_categorical_accuracy: 0.6875\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-2216_44_36.385184/model-00015-0.56183-0.78711-0.98399-0.68750.h5\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - 41s 2s/step - loss: 0.5722 - categorical_accuracy: 0.7647 - val_loss: 0.6512 - val_categorical_accuracy: 0.8125\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-2216_44_36.385184/model-00016-0.57224-0.76471-0.65115-0.81250.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - 42s 2s/step - loss: 0.5361 - categorical_accuracy: 0.7759 - val_loss: 0.5345 - val_categorical_accuracy: 0.8125\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-2216_44_36.385184/model-00017-0.53612-0.77591-0.53448-0.81250.h5\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - 41s 2s/step - loss: 0.6021 - categorical_accuracy: 0.7787 - val_loss: 0.7002 - val_categorical_accuracy: 0.6875\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-2216_44_36.385184/model-00018-0.60208-0.77871-0.70025-0.68750.h5\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - 42s 2s/step - loss: 0.5005 - categorical_accuracy: 0.7983 - val_loss: 0.6004 - val_categorical_accuracy: 0.8125\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-2216_44_36.385184/model-00019-0.50047-0.79832-0.60035-0.81250.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - 43s 2s/step - loss: 0.5585 - categorical_accuracy: 0.7927 - val_loss: 0.9534 - val_categorical_accuracy: 0.8125\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-2216_44_36.385184/model-00020-0.55848-0.79272-0.95341-0.81250.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bb27fa358>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "    \n",
    "model_f.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Above Model Gives Desired Accuracy of 79.2% in Training and 81.2% in validation.It shows that model is stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ./Project_data/valSource path =  ./Project_data/train ; batch size = 64\n",
      "Epoch 1/20\n",
      " ; batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  2 Index: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/11 [====>.........................] - ETA: 1:23 - loss: 0.4252 - categorical_accuracy: 0.8594Batch:  3 Index: 36\n",
      " 4/11 [=========>....................] - ETA: 1:04 - loss: 0.4426 - categorical_accuracy: 0.8359Batch:  4 Index: 28\n",
      " 9/11 [=======================>......] - ETA: 16s - loss: 0.5186 - categorical_accuracy: 0.7934Batch:  11 Index: 64\n",
      "11/11 [==============================] - 88s 8s/step - loss: 0.5546 - categorical_accuracy: 0.7862 - val_loss: 0.6799 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2216_44_36.385184/model-00001-0.54369-0.78884-0.67994-0.79000.h5\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.5766 - categorical_accuracy: 0.7866 - val_loss: 0.7588 - val_categorical_accuracy: 0.7778\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2216_44_36.385184/model-00002-0.57663-0.78656-0.75881-0.77778.h5\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.5635 - categorical_accuracy: 0.8103 - val_loss: 0.8376 - val_categorical_accuracy: 0.6607\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2216_44_36.385184/model-00003-0.56345-0.81028-0.83758-0.66071.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 4/20\n",
      "Batch:  7 Index: 16\n",
      " 5/11 [============>.................] - ETA: 15s - loss: 0.4893 - categorical_accuracy: 0.8174Batch:  29 Index: 23\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.5707 - categorical_accuracy: 0.7929 - val_loss: 0.6306 - val_categorical_accuracy: 0.8393\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2216_44_36.385184/model-00004-0.56437-0.79399-0.63062-0.83929.h5\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.4960 - categorical_accuracy: 0.8230 - val_loss: 0.6241 - val_categorical_accuracy: 0.7188\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2216_44_36.385184/model-00005-0.49600-0.82297-0.62411-0.71875.h5\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.5129 - categorical_accuracy: 0.7799 - val_loss: 0.7741 - val_categorical_accuracy: 0.8125\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2216_44_36.385184/model-00006-0.51293-0.77990-0.77407-0.81250.h5\n",
      "Epoch 7/20\n",
      " 7/11 [==================>...........] - ETA: 8s - loss: 0.6919 - categorical_accuracy: 0.7068 Batch:  35 Index: 19\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.6524 - categorical_accuracy: 0.7401 - val_loss: 0.6066 - val_categorical_accuracy: 0.8438\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2216_44_36.385184/model-00007-0.65365-0.73892-0.60659-0.84375.h5\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 20s 2s/step - loss: 0.5313 - categorical_accuracy: 0.7968 - val_loss: 0.7500 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2216_44_36.385184/model-00008-0.53127-0.79679-0.74996-0.80000.h5\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 20s 2s/step - loss: 0.5784 - categorical_accuracy: 0.7433 - val_loss: 0.9432 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-2216_44_36.385184/model-00013-0.57845-0.74332-0.94324-0.75000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.5969 - categorical_accuracy: 0.7701 - val_loss: 0.5231 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-2216_44_36.385184/model-00014-0.59690-0.77005-0.52311-0.75000.h5\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.6026 - categorical_accuracy: 0.7701 - val_loss: 0.4121 - val_categorical_accuracy: 0.8750\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-2216_44_36.385184/model-00015-0.60260-0.77005-0.41212-0.87500.h5\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 21s 2s/step - loss: 0.5761 - categorical_accuracy: 0.7540 - val_loss: 0.5486 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-2216_44_36.385184/model-00016-0.57614-0.75401-0.54856-0.75000.h5\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.6574 - categorical_accuracy: 0.7647 - val_loss: 1.2872 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-2216_44_36.385184/model-00017-0.65744-0.76471-1.28722-0.50000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.6207 - categorical_accuracy: 0.7433 - val_loss: 0.3891 - val_categorical_accuracy: 0.8750\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-2216_44_36.385184/model-00018-0.62070-0.74332-0.38913-0.87500.h5\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.5458 - categorical_accuracy: 0.7914 - val_loss: 0.6321 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-2216_44_36.385184/model-00019-0.54582-0.79144-0.63212-0.75000.h5\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 21s 2s/step - loss: 0.5295 - categorical_accuracy: 0.8021 - val_loss: 0.3822 - val_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-2216_44_36.385184/model-00020-0.52950-0.80214-0.38223-1.00000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bb278e828>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 20\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "    \n",
    "model_f.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ./Project_data/val ; batch size = 40\n",
      "Source path =  ./Project_data/train ; batch size = 40\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/17 [==>...........................] - ETA: 1:33 - loss: 0.5346 - categorical_accuracy: 0.8125Batch:  3 Index: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/17 [=========================>....] - ETA: 10s - loss: 0.5920 - categorical_accuracy: 0.7483Batch:  17 Index: 40\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.5848 - categorical_accuracy: 0.7558 - val_loss: 0.7091 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2216_44_36.385184/model-00001-0.58740-0.75415-0.70910-0.77000.h5\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.5077 - categorical_accuracy: 0.7928 - val_loss: 0.8271 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2216_44_36.385184/model-00002-0.50770-0.79284-0.82710-0.71667.h5\n",
      "Epoch 3/20\n",
      "10/17 [================>.............] - ETA: 19s - loss: 0.6397 - categorical_accuracy: 0.7739Batch:  29 Index: 23\n",
      "17/17 [==============================] - 44s 3s/step - loss: 0.6154 - categorical_accuracy: 0.7783 - val_loss: 0.6509 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2216_44_36.385184/model-00003-0.61958-0.77657-0.65085-0.80000.h5\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.6418 - categorical_accuracy: 0.7337 - val_loss: 0.7181 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2216_44_36.385184/model-00004-0.64182-0.73375-0.71814-0.76667.h5\n",
      "Epoch 5/20\n",
      "11/17 [==================>...........] - ETA: 14s - loss: 0.4931 - categorical_accuracy: 0.8230Batch:  35 Index: 19\n",
      "17/17 [==============================] - 40s 2s/step - loss: 0.5091 - categorical_accuracy: 0.8184 - val_loss: 0.5726 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2216_44_36.385184/model-00005-0.50815-0.81789-0.57265-0.78333.h5\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.5741 - categorical_accuracy: 0.7889 - val_loss: 0.8265 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2216_44_36.385184/model-00006-0.57408-0.78893-0.82653-0.73333.h5\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.5259 - categorical_accuracy: 0.8097 - val_loss: 0.7109 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2216_44_36.385184/model-00007-0.52594-0.80969-0.71088-0.76667.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 36s 2s/step - loss: 0.6024 - categorical_accuracy: 0.7820 - val_loss: 0.7854 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2216_44_36.385184/model-00008-0.60242-0.78201-0.78543-0.76667.h5\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.6021 - categorical_accuracy: 0.7924 - val_loss: 0.6259 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-2216_44_36.385184/model-00009-0.60207-0.79239-0.62588-0.80000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.5804 - categorical_accuracy: 0.7889 - val_loss: 0.6670 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-2216_44_36.385184/model-00010-0.58037-0.78893-0.66697-0.80000.h5\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.5132 - categorical_accuracy: 0.8166 - val_loss: 0.8076 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-2216_44_36.385184/model-00011-0.51318-0.81661-0.80759-0.71667.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.5918 - categorical_accuracy: 0.7578 - val_loss: 0.7616 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-2216_44_36.385184/model-00012-0.59184-0.75779-0.76162-0.78333.h5\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 37s 2s/step - loss: 0.5592 - categorical_accuracy: 0.8131 - val_loss: 0.7088 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-2216_44_36.385184/model-00013-0.55920-0.81315-0.70884-0.73333.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.5582 - categorical_accuracy: 0.7509 - val_loss: 0.6335 - val_categorical_accuracy: 0.8333\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-2216_44_36.385184/model-00014-0.55825-0.75087-0.63346-0.83333.h5\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 36s 2s/step - loss: 0.5508 - categorical_accuracy: 0.7716 - val_loss: 0.7894 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-2216_44_36.385184/model-00015-0.55076-0.77163-0.78943-0.71667.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.5630 - categorical_accuracy: 0.7647 - val_loss: 0.7026 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-2216_44_36.385184/model-00016-0.56304-0.76471-0.70263-0.80000.h5\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 36s 2s/step - loss: 0.5958 - categorical_accuracy: 0.7647 - val_loss: 0.7486 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-2216_44_36.385184/model-00017-0.59578-0.76471-0.74864-0.78333.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.5922 - categorical_accuracy: 0.7820 - val_loss: 0.6268 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-2216_44_36.385184/model-00018-0.59221-0.78201-0.62682-0.80000.h5\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.4729 - categorical_accuracy: 0.8131 - val_loss: 0.7608 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-2216_44_36.385184/model-00019-0.47291-0.81315-0.76084-0.78333.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.5268 - categorical_accuracy: 0.7889 - val_loss: 0.6954 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-2216_44_36.385184/model-00020-0.52682-0.78893-0.69545-0.73333.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bb278e320>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 40\n",
    "num_epochs = 20\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "model_f.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN+RNN Stack using GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "    \n",
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height \n",
    "\n",
    "n_classes = 5\n",
    "n_channel = 3\n",
    "\n",
    "# Input\n",
    "input_shape=(x,y,z,n_channel)\n",
    "\n",
    "    \n",
    "    \n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(120,120,3))\n",
    "cnn_out = base_model.output\n",
    "cnn_out = Flatten()(cnn_out)\n",
    "\n",
    "features = Dense(64, activation='relu')(cnn_out)\n",
    "conv_model = Model(inputs=base_model.input, outputs=features)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "        \n",
    "model_gpu = Sequential()\n",
    "model_gpu.add(TimeDistributed(conv_model, input_shape=input_shape))\n",
    "model_gpu.add(GRU(32, return_sequences=True))\n",
    "model_gpu.add(GRU(16))\n",
    "model_gpu.add(Dropout(0.5))\n",
    "model_gpu.add(Dense(8, activation='relu'))\n",
    "model_gpu.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_2 (TimeDist (None, 30, 64)            15009664  \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 30, 32)            9312      \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 16)                2352      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 45        \n",
      "=================================================================\n",
      "Total params: 15,021,509\n",
      "Trainable params: 306,821\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model_gpu.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_gpu.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ./Project_data/val ; batch size = 10\n",
      "Source path =  ./Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/67 [============================>.] - ETA: 2s - loss: 0.5841 - categorical_accuracy: 0.8646Batch:  67 Index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 97s 1s/step - loss: 0.5783 - categorical_accuracy: 0.8671 - val_loss: 0.7930 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2217_59_43.925201/model-00001-0.58035-0.86576-0.79300-0.77000.h5\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 34s 506ms/step - loss: 0.5008 - categorical_accuracy: 0.9204 - val_loss: 0.8250 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2217_59_43.925201/model-00002-0.50078-0.92040-0.82500-0.77000.h5\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 34s 503ms/step - loss: 0.5476 - categorical_accuracy: 0.8706 - val_loss: 0.7480 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2217_59_43.925201/model-00003-0.54761-0.87065-0.74798-0.75000.h5\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 34s 504ms/step - loss: 0.5631 - categorical_accuracy: 0.8856 - val_loss: 0.7798 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2217_59_43.925201/model-00004-0.56312-0.88557-0.77977-0.75000.h5\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 34s 504ms/step - loss: 0.5030 - categorical_accuracy: 0.9055 - val_loss: 0.8952 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2217_59_43.925201/model-00005-0.50300-0.90547-0.89524-0.69000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 34s 503ms/step - loss: 0.5454 - categorical_accuracy: 0.9104 - val_loss: 0.7804 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2217_59_43.925201/model-00006-0.54543-0.91045-0.78043-0.76000.h5\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 34s 506ms/step - loss: 0.4871 - categorical_accuracy: 0.9055 - val_loss: 0.7667 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2217_59_43.925201/model-00007-0.48714-0.90547-0.76667-0.76000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 34s 503ms/step - loss: 0.4955 - categorical_accuracy: 0.9055 - val_loss: 0.7791 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2217_59_43.925201/model-00008-0.49555-0.90547-0.77914-0.74000.h5\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 34s 505ms/step - loss: 0.5346 - categorical_accuracy: 0.9154 - val_loss: 0.7844 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-2217_59_43.925201/model-00009-0.53461-0.91542-0.78442-0.74000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 34s 505ms/step - loss: 0.4531 - categorical_accuracy: 0.9055 - val_loss: 0.7686 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-2217_59_43.925201/model-00010-0.45306-0.90547-0.76864-0.74000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7ba2ed0c18>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "model_gpu.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ./Project_data/val ; batch size = 32\n",
      "Source path =  ./Project_data/trainEpoch 1/20\n",
      " ; batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  4 Index: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/21 [==========================>...] - ETA: 8s - loss: 1.6225 - categorical_accuracy: 0.2401 Batch:  21 Index: 32\n",
      "21/21 [==============================] - 113s 5s/step - loss: 1.6177 - categorical_accuracy: 0.2395 - val_loss: 1.5341 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2217_59_43.925201/model-00001-1.61816-0.23982-1.53408-0.35000.h5\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - 42s 2s/step - loss: 1.5071 - categorical_accuracy: 0.3478 - val_loss: 1.5092 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2217_59_43.925201/model-00002-1.50714-0.34783-1.50925-0.50000.h5\n",
      "Epoch 3/20\n",
      " 4/21 [====>.........................] - ETA: 32s - loss: 1.5444 - categorical_accuracy: 0.3152Batch:  29 Index: 23\n",
      "21/21 [==============================] - 48s 2s/step - loss: 1.4286 - categorical_accuracy: 0.3961 - val_loss: 1.3046 - val_categorical_accuracy: 0.4375\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2217_59_43.925201/model-00003-1.43365-0.39344-1.30457-0.43750.h5\n",
      "Epoch 4/20\n",
      "20/21 [===========================>..] - ETA: 2s - loss: 1.3161 - categorical_accuracy: 0.4737Batch:  35 Index: 19\n",
      "21/21 [==============================] - 46s 2s/step - loss: 1.3240 - categorical_accuracy: 0.4637 - val_loss: 1.3253 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2217_59_43.925201/model-00004-1.32398-0.46366-1.32535-0.62500.h5\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - 44s 2s/step - loss: 1.2086 - categorical_accuracy: 0.5238 - val_loss: 1.3271 - val_categorical_accuracy: 0.3125\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2217_59_43.925201/model-00005-1.20862-0.52381-1.32708-0.31250.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - 43s 2s/step - loss: 1.1584 - categorical_accuracy: 0.5770 - val_loss: 1.2698 - val_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2217_59_43.925201/model-00006-1.15843-0.57703-1.26979-0.56250.h5\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - 46s 2s/step - loss: 1.0445 - categorical_accuracy: 0.6134 - val_loss: 0.8986 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2217_59_43.925201/model-00007-1.04450-0.61345-0.89860-0.75000.h5\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - 43s 2s/step - loss: 0.9448 - categorical_accuracy: 0.7031 - val_loss: 1.0060 - val_categorical_accuracy: 0.6875\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2217_59_43.925201/model-00008-0.94478-0.70308-1.00600-0.68750.h5\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - 44s 2s/step - loss: 0.9122 - categorical_accuracy: 0.7171 - val_loss: 1.0221 - val_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-2217_59_43.925201/model-00009-0.91216-0.71709-1.02207-0.56250.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - 45s 2s/step - loss: 0.8893 - categorical_accuracy: 0.7031 - val_loss: 1.1747 - val_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-2217_59_43.925201/model-00010-0.88934-0.70308-1.17475-0.56250.h5\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - 45s 2s/step - loss: 0.7987 - categorical_accuracy: 0.7703 - val_loss: 0.7835 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-2217_59_43.925201/model-00011-0.79869-0.77031-0.78350-0.75000.h5\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - 45s 2s/step - loss: 0.7427 - categorical_accuracy: 0.7675 - val_loss: 0.9507 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-2217_59_43.925201/model-00012-0.74270-0.76751-0.95071-0.75000.h5\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - 43s 2s/step - loss: 0.7515 - categorical_accuracy: 0.7955 - val_loss: 0.7421 - val_categorical_accuracy: 0.8125\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-2217_59_43.925201/model-00013-0.75147-0.79552-0.74210-0.81250.h5\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - 46s 2s/step - loss: 0.7302 - categorical_accuracy: 0.7899 - val_loss: 1.0370 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-2217_59_43.925201/model-00014-0.73024-0.78992-1.03702-0.62500.h5\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - 43s 2s/step - loss: 0.6819 - categorical_accuracy: 0.8067 - val_loss: 0.8670 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-2217_59_43.925201/model-00015-0.68191-0.80672-0.86699-0.75000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - 42s 2s/step - loss: 0.6369 - categorical_accuracy: 0.8347 - val_loss: 0.6993 - val_categorical_accuracy: 0.8125\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-2217_59_43.925201/model-00016-0.63690-0.83473-0.69930-0.81250.h5\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - 47s 2s/step - loss: 0.6321 - categorical_accuracy: 0.8487 - val_loss: 0.7652 - val_categorical_accuracy: 0.8125\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-2217_59_43.925201/model-00017-0.63207-0.84874-0.76516-0.81250.h5\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - 44s 2s/step - loss: 0.6202 - categorical_accuracy: 0.8571 - val_loss: 1.0464 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-2217_59_43.925201/model-00018-0.62020-0.85714-1.04641-0.62500.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - 44s 2s/step - loss: 0.5912 - categorical_accuracy: 0.8375 - val_loss: 0.6402 - val_categorical_accuracy: 0.8750\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-2217_59_43.925201/model-00019-0.59117-0.83754-0.64021-0.87500.h5\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - 43s 2s/step - loss: 0.5723 - categorical_accuracy: 0.8739 - val_loss: 0.8237 - val_categorical_accuracy: 0.6875\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-2217_59_43.925201/model-00020-0.57227-0.87395-0.82375-0.68750.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7ba306f940>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "model_gpu.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Final Model -CNN+RNN Stack using GRU with BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_8 (TimeDist (None, 30, 64)            15009664  \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 30, 32)            9312      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30, 32)            128       \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 16)                2352      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 5)                 45        \n",
      "=================================================================\n",
      "Total params: 15,021,637\n",
      "Trainable params: 306,885\n",
      "Non-trainable params: 14,714,752\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "    \n",
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height \n",
    "\n",
    "n_classes = 5\n",
    "n_channel = 3\n",
    "\n",
    "# Input\n",
    "input_shape=(x,y,z,n_channel)\n",
    "   \n",
    "    \n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(120,120,3))\n",
    "cnn_out = base_model.output\n",
    "cnn_out = Flatten()(cnn_out)\n",
    "\n",
    "features = Dense(64, activation='relu')(cnn_out)\n",
    "conv_model = Model(inputs=base_model.input, outputs=features)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "        \n",
    "model_gpu1 = Sequential()\n",
    "model_gpu1.add(TimeDistributed(conv_model, input_shape=input_shape))\n",
    "model_gpu1.add(GRU(32, return_sequences=True))\n",
    "model_gpu1.add(BatchNormalization())\n",
    "model_gpu1.add(GRU(16))\n",
    "model_gpu1.add(Dropout(0.5))\n",
    "model_gpu1.add(Dense(8, activation='relu'))\n",
    "model_gpu1.add(Dense(5, activation='softmax'))\n",
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model_gpu1.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_gpu1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ./Project_data/val ; batch size = 32\n",
      "Source path =  ./Project_data/train ; batch size = 32\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  4 Index: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/21 [==========================>...] - ETA: 16s - loss: 1.5990 - categorical_accuracy: 0.3109Batch:  21 Index: 32\n",
      "21/21 [==============================] - 193s 9s/step - loss: 1.5840 - categorical_accuracy: 0.3192 - val_loss: 1.5133 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2309_36_12.102624/model-00001-1.58564-0.31825-1.51330-0.41000.h5\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - 42s 2s/step - loss: 1.2766 - categorical_accuracy: 0.4990 - val_loss: 1.2000 - val_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2309_36_12.102624/model-00002-1.27655-0.49896-1.19996-0.56250.h5\n",
      "Epoch 3/20\n",
      " 6/21 [=======>......................] - ETA: 28s - loss: 1.2262 - categorical_accuracy: 0.5290Batch:  29 Index: 23\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.1375 - categorical_accuracy: 0.5931 - val_loss: 1.2358 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2309_36_12.102624/model-00003-1.14134-0.59016-1.23582-0.50000.h5\n",
      "Epoch 4/20\n",
      "20/21 [===========================>..] - ETA: 2s - loss: 0.9838 - categorical_accuracy: 0.6816Batch:  35 Index: 19\n",
      "21/21 [==============================] - 46s 2s/step - loss: 0.9753 - categorical_accuracy: 0.6867 - val_loss: 1.3010 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2309_36_12.102624/model-00004-0.97535-0.68672-1.30096-0.50000.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - 44s 2s/step - loss: 0.7887 - categorical_accuracy: 0.7871 - val_loss: 1.1176 - val_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2309_36_12.102624/model-00005-0.78872-0.78711-1.11758-0.37500.h5\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - 42s 2s/step - loss: 0.7751 - categorical_accuracy: 0.7591 - val_loss: 0.7302 - val_categorical_accuracy: 0.6875\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2309_36_12.102624/model-00006-0.77510-0.75910-0.73018-0.68750.h5\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - 44s 2s/step - loss: 0.6484 - categorical_accuracy: 0.8431 - val_loss: 1.1417 - val_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2309_36_12.102624/model-00007-0.64835-0.84314-1.14166-0.56250.h5\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - 44s 2s/step - loss: 0.6293 - categorical_accuracy: 0.8179 - val_loss: 0.9056 - val_categorical_accuracy: 0.6875\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2309_36_12.102624/model-00008-0.62930-0.81793-0.90563-0.68750.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - 43s 2s/step - loss: 0.5126 - categorical_accuracy: 0.8908 - val_loss: 0.6886 - val_categorical_accuracy: 0.8125\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-2309_36_12.102624/model-00009-0.51262-0.89076-0.68858-0.81250.h5\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - 43s 2s/step - loss: 0.4691 - categorical_accuracy: 0.9048 - val_loss: 0.8119 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-2309_36_12.102624/model-00010-0.46907-0.90476-0.81185-0.75000.h5\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - 44s 2s/step - loss: 0.4569 - categorical_accuracy: 0.9160 - val_loss: 0.5117 - val_categorical_accuracy: 0.9375\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-2309_36_12.102624/model-00011-0.45688-0.91597-0.51169-0.93750.h5\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - 45s 2s/step - loss: 0.4693 - categorical_accuracy: 0.8992 - val_loss: 0.5098 - val_categorical_accuracy: 0.8750\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-2309_36_12.102624/model-00012-0.46934-0.89916-0.50982-0.87500.h5\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - 41s 2s/step - loss: 0.4279 - categorical_accuracy: 0.9104 - val_loss: 0.6951 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-2309_36_12.102624/model-00013-0.42787-0.91036-0.69506-0.75000.h5\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - 43s 2s/step - loss: 0.4030 - categorical_accuracy: 0.9104 - val_loss: 0.6983 - val_categorical_accuracy: 0.8125\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-2309_36_12.102624/model-00014-0.40297-0.91036-0.69831-0.81250.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - 44s 2s/step - loss: 0.3593 - categorical_accuracy: 0.9244 - val_loss: 1.0760 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-2309_36_12.102624/model-00015-0.35933-0.92437-1.07604-0.62500.h5\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - 42s 2s/step - loss: 0.3691 - categorical_accuracy: 0.9272 - val_loss: 0.9124 - val_categorical_accuracy: 0.6875\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-2309_36_12.102624/model-00016-0.36913-0.92717-0.91244-0.68750.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - 44s 2s/step - loss: 0.3580 - categorical_accuracy: 0.9440 - val_loss: 0.4704 - val_categorical_accuracy: 0.8750\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-2309_36_12.102624/model-00017-0.35802-0.94398-0.47043-0.87500.h5\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - 41s 2s/step - loss: 0.3405 - categorical_accuracy: 0.9524 - val_loss: 0.3905 - val_categorical_accuracy: 0.9375\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-2309_36_12.102624/model-00018-0.34045-0.95238-0.39046-0.93750.h5\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - 44s 2s/step - loss: 0.3269 - categorical_accuracy: 0.9580 - val_loss: 0.5179 - val_categorical_accuracy: 0.8125\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-2309_36_12.102624/model-00019-0.32694-0.95798-0.51788-0.81250.h5\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - 44s 2s/step - loss: 0.3425 - categorical_accuracy: 0.9384 - val_loss: 0.4459 - val_categorical_accuracy: 0.9375\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-2309_36_12.102624/model-00020-0.34248-0.93838-0.44590-0.93750.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1d1eb34f60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "model_gpu1.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Above Model Gives Desired Accuracy of 93.84% in Training and 93.75% in validation,It shows model is stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ./Project_data/val ; batch size = 16\n",
      "Source path =  ./Project_data/train ; batch size = 16\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/42 [==>...........................] - ETA: 1:46 - loss: 1.8546 - categorical_accuracy: 0.2125Batch:  7 Index: 16\n",
      " 6/42 [===>..........................] - ETA: 1:41 - loss: 1.8515 - categorical_accuracy: 0.2188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/42 [===========================>..] - ETA: 4s - loss: 1.5999 - categorical_accuracy: 0.3203Batch:  42 Index: 16\n",
      "42/42 [==============================] - 92s 2s/step - loss: 1.5914 - categorical_accuracy: 0.3271 - val_loss: 1.4233 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-2309_36_12.102624/model-00001-1.59453-0.32579-1.42328-0.36000.h5\n",
      "Epoch 2/30\n",
      "42/42 [==============================] - 32s 757ms/step - loss: 1.3335 - categorical_accuracy: 0.4558 - val_loss: 1.2119 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-2309_36_12.102624/model-00002-1.33347-0.45578-1.21195-0.50000.h5\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 37s 884ms/step - loss: 1.2277 - categorical_accuracy: 0.4762 - val_loss: 1.1184 - val_categorical_accuracy: 0.4286\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-2309_36_12.102624/model-00003-1.22767-0.47619-1.11845-0.42857.h5\n",
      "Epoch 4/30\n",
      " 8/42 [====>.........................] - ETA: 23s - loss: 1.3487 - categorical_accuracy: 0.4286Batch:  95 Index: 7\n",
      "42/42 [==============================] - 29s 683ms/step - loss: 1.2129 - categorical_accuracy: 0.5468 - val_loss: 1.4730 - val_categorical_accuracy: 0.3929\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-2309_36_12.102624/model-00004-1.22610-0.53913-1.47302-0.39286.h5\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 26s 629ms/step - loss: 1.1130 - categorical_accuracy: 0.5810 - val_loss: 1.7376 - val_categorical_accuracy: 0.2857\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-2309_36_12.102624/model-00005-1.11301-0.58095-1.73757-0.28571.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 27s 653ms/step - loss: 1.0958 - categorical_accuracy: 0.5524 - val_loss: 0.8390 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-2309_36_12.102624/model-00006-1.09583-0.55238-0.83903-0.75000.h5\n",
      "Epoch 7/30\n",
      "14/42 [=========>....................] - ETA: 14s - loss: 1.0300 - categorical_accuracy: 0.5714Batch:  133 Index: 5\n",
      "42/42 [==============================] - 20s 488ms/step - loss: 1.1109 - categorical_accuracy: 0.5399 - val_loss: 1.1766 - val_categorical_accuracy: 0.5714\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-2309_36_12.102624/model-00007-1.09600-0.55000-1.17664-0.57143.h5\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 18s 433ms/step - loss: 1.0899 - categorical_accuracy: 0.5635 - val_loss: 1.0252 - val_categorical_accuracy: 0.6429\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-2309_36_12.102624/model-00008-1.08985-0.56349-1.02516-0.64286.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 18s 433ms/step - loss: 1.1827 - categorical_accuracy: 0.5159 - val_loss: 0.9483 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-2309_36_12.102624/model-00009-1.18272-0.51587-0.94833-0.50000.h5\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 18s 431ms/step - loss: 0.9834 - categorical_accuracy: 0.6429 - val_loss: 0.8382 - val_categorical_accuracy: 0.6786\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-2309_36_12.102624/model-00010-0.98337-0.64286-0.83815-0.67857.h5\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 18s 426ms/step - loss: 0.9495 - categorical_accuracy: 0.6667 - val_loss: 0.9943 - val_categorical_accuracy: 0.6429\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-2309_36_12.102624/model-00011-0.94947-0.66667-0.99431-0.64286.h5\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 18s 427ms/step - loss: 1.0248 - categorical_accuracy: 0.5873 - val_loss: 0.8947 - val_categorical_accuracy: 0.7143\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-2309_36_12.102624/model-00012-1.02485-0.58730-0.89475-0.71429.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 18s 431ms/step - loss: 0.8731 - categorical_accuracy: 0.6508 - val_loss: 0.9243 - val_categorical_accuracy: 0.6429\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-2309_36_12.102624/model-00013-0.87309-0.65079-0.92425-0.64286.h5\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 18s 429ms/step - loss: 0.8375 - categorical_accuracy: 0.7222 - val_loss: 0.9093 - val_categorical_accuracy: 0.6429\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-2309_36_12.102624/model-00014-0.83754-0.72222-0.90927-0.64286.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 18s 433ms/step - loss: 0.9181 - categorical_accuracy: 0.6587 - val_loss: 0.8011 - val_categorical_accuracy: 0.7857\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-2309_36_12.102624/model-00015-0.91807-0.65873-0.80108-0.78571.h5\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 18s 426ms/step - loss: 0.9591 - categorical_accuracy: 0.6429 - val_loss: 0.7265 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-2309_36_12.102624/model-00016-0.95909-0.64286-0.72649-0.75000.h5\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 18s 428ms/step - loss: 0.7945 - categorical_accuracy: 0.7540 - val_loss: 0.7993 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-2309_36_12.102624/model-00017-0.79449-0.75397-0.79932-0.75000.h5\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 18s 425ms/step - loss: 0.8087 - categorical_accuracy: 0.7143 - val_loss: 0.8718 - val_categorical_accuracy: 0.6071\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-2309_36_12.102624/model-00018-0.80866-0.71429-0.87176-0.60714.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 18s 425ms/step - loss: 0.8356 - categorical_accuracy: 0.6667 - val_loss: 0.9726 - val_categorical_accuracy: 0.6429\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-2309_36_12.102624/model-00019-0.83558-0.66667-0.97258-0.64286.h5\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 18s 426ms/step - loss: 0.9109 - categorical_accuracy: 0.6190 - val_loss: 0.8259 - val_categorical_accuracy: 0.7857\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-2309_36_12.102624/model-00020-0.91087-0.61905-0.82590-0.78571.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 18s 427ms/step - loss: 1.0123 - categorical_accuracy: 0.6190 - val_loss: 0.7671 - val_categorical_accuracy: 0.6786\n",
      "\n",
      "Epoch 00021: saving model to model_init_2019-09-2309_36_12.102624/model-00021-1.01225-0.61905-0.76707-0.67857.h5\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 18s 428ms/step - loss: 0.9360 - categorical_accuracy: 0.6429 - val_loss: 0.8631 - val_categorical_accuracy: 0.6429\n",
      "\n",
      "Epoch 00022: saving model to model_init_2019-09-2309_36_12.102624/model-00022-0.93598-0.64286-0.86308-0.64286.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 18s 425ms/step - loss: 0.9302 - categorical_accuracy: 0.6984 - val_loss: 0.9166 - val_categorical_accuracy: 0.6071\n",
      "\n",
      "Epoch 00023: saving model to model_init_2019-09-2309_36_12.102624/model-00023-0.93022-0.69841-0.91663-0.60714.h5\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 18s 428ms/step - loss: 0.8587 - categorical_accuracy: 0.7222 - val_loss: 0.7592 - val_categorical_accuracy: 0.7143\n",
      "\n",
      "Epoch 00029: saving model to model_init_2019-09-2309_36_12.102624/model-00029-0.85874-0.72222-0.75916-0.71429.h5\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 18s 428ms/step - loss: 0.8424 - categorical_accuracy: 0.7381 - val_loss: 0.7760 - val_categorical_accuracy: 0.8571\n",
      "\n",
      "Epoch 00030: saving model to model_init_2019-09-2309_36_12.102624/model-00030-0.84238-0.73810-0.77597-0.85714.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1cabe24fd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 30\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "model_gpu1.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model -CNN+RNN Stack using GRU\n",
    "\n",
    "<font color='blue'> Batch_size = 32 and num_epochs = 20 ,\n",
    " </font><br>\n",
    "<font color='red'>In 20th epoch-> train accuracy = 93.84% And Validation Accuracy = 93.75%\n",
    "</font><br>\n",
    "\n",
    "__.h5 file__<br>\n",
    "In 20th epoch ==> model_init_2019-09-2309_36_12.102624/model-00020-0.34248-0.93838-0.44590-0.93750.h5\n",
    "\n",
    "Google Drive Link: https://drive.google.com/open?id=1JSUj7mxOwbD-nqseNIVZwWDEDMY_JuO2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final 3D Convolutional Network  \n",
    "\n",
    "<font color='blue'> Batch_size = 32 and num_epochs = 20 ,\n",
    "nb_filters = [8,16,32,64] ,\n",
    "nb_dense = [256, 128, 5]\n",
    "\n",
    "number of frames =30 ,\n",
    "image width = 120 ,\n",
    "image height = 120 \n",
    "n_classes = 5, \n",
    "n_channel = 3 </font><br>\n",
    "<font color='red'>In 20th epoch-> train accuracy = 79.2% And Validation Accuracy = 81.2%\n",
    "</font><br>\n",
    "\n",
    "__.h5 file__<br>\n",
    "In 20th epoch ==> model_init_2019-09-2216_44_36.385184/model-00020-0.55848-0.79272-0.95341-0.81250.h5\n",
    "\n",
    "Google Drive Link: https://drive.google.com/open?id=1T27pUpS-hVxGqhUQDwhmzRqRvCW3dXFs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
